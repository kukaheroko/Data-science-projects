{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------import libraries and data--------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the dataset in dataframe using pandas\n",
    "df = pd.read_csv('train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------quick data exploration-------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print first 10 rows of dataset\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get summary of numerical variables\n",
    "df.describe()\n",
    "\n",
    "# Few inferences from summary of numerical variables:\n",
    "# LoanAmount has (614 – 592) 22 missing values.\n",
    "# Loan_Amount_Term has (614 – 600) 14 missing values.\n",
    "# Credit_History has (614 – 564) 50 missing values.\n",
    "# We can also look that about 84% applicants have a credit_history. {How? \n",
    "#     The mean of Credit_History field is 0.84 (Remember, Credit_History \n",
    "#     has value 1 for those who have a credit history and 0 otherwise)}\n",
    "# The ApplicantIncome distribution seems to be in line with expectation. Same with CoapplicantIncome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequency distributions for non-numerical variables\n",
    "\n",
    "# Gender frequencies\n",
    "df['Gender'].value_counts()\n",
    "\n",
    "# Married frequencies\n",
    "df['Married'].value_counts()\n",
    "\n",
    "# Dependents frequencies\n",
    "df['Dependents'].value_counts()\n",
    "\n",
    "# Education frequencies\n",
    "df['Education'].value_counts()\n",
    "\n",
    "# Self_Employed frequencies\n",
    "df['Self_Employed'].value_counts()\n",
    "\n",
    "# Credit_History frequencies\n",
    "df['Credit_History'].value_counts()\n",
    "\n",
    "# Property_Area frequencies\n",
    "df['Property_Area'].value_counts()\n",
    "\n",
    "# Loan_Status frequencies\n",
    "df['Loan_Status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------Distribution analysis----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the histogram of ApplicantIncome\n",
    "df['ApplicantIncome'].hist(bins=50)\n",
    "\n",
    "# box plot of ApplicantIncome\n",
    "df.boxplot(column='ApplicantIncome')\n",
    "\n",
    "# This confirms the presence of a lot of outliers/extreme values. \n",
    "# This can be attributed to the income disparity in the society. Part \n",
    "# of this can be driven by the fact that we are looking at people with \n",
    "# different education levels. Let us segregate them by Education:\n",
    "df.boxplot(column='ApplicantIncome', by='Education')\n",
    "\n",
    "# We can see that there is no substantial different between the mean income \n",
    "# of graduate and non-graduates. But there are a higher number of graduates \n",
    "# with very high incomes, which are appearing to be the outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting histogram of LoanAmount\n",
    "df['LoanAmount'].hist(bins=50)\n",
    "\n",
    "# box plot of LoanAmount\n",
    "df.boxplot(column='LoanAmount')\n",
    "\n",
    "# extreme values present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------Categorical variable analysis-----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Credit_History_freq = df['Credit_History'].value_counts(ascending=True)\n",
    "print('Frequency Table for Credit History:')\n",
    "print(Credit_History_freq)\n",
    "\n",
    "P_by_CreditHistory_class = df.pivot_table(values='Loan_Status', index=['Credit_History'], aggfunc=lambda x: x.map(\n",
    "    {'Y': 1, 'N': 0}).mean())\n",
    "print('\\nProbability of getting loan for each Credit History class:')\n",
    "print(P_by_CreditHistory_class)\n",
    "P_by_CreditHistory_class = P_by_CreditHistory_class.squeeze()\n",
    "\n",
    "fig = plt.figure(figsize=(8, 4))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.set_xlabel('Credit_History')\n",
    "ax1.set_ylabel('Count of Applicants')\n",
    "ax1.set_title(\"Applicants by Credit_History\")\n",
    "Credit_History_freq.plot(kind='bar')\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "ax2.set_xlabel('Credit_History')\n",
    "ax2.set_ylabel('Probability of getting loan')\n",
    "ax2.set_title(\"Probability of getting loan by credit history\")\n",
    "P_by_CreditHistory_class.plot(kind='bar')\n",
    "# chances of getting a loan are eight-fold if the applicant has a valid credit history\n",
    "\n",
    "CreditHistory_LoanStatus_comb_stacked = pd.crosstab(df['Credit_History'], df['Loan_Status'])\n",
    "CreditHistory_LoanStatus_comb_stacked.plot(kind='bar', stacked=True, color=['red', 'blue'], grid=False)\n",
    "\n",
    "CreditHistoryGender_LoanStatus_comb_stacked = pd.crosstab([df['Credit_History'], df['Gender']], df['Loan_Status'])\n",
    "CreditHistoryGender_LoanStatus_comb_stacked.plot(kind='bar', stacked=True, color=['red', 'blue'], grid=False)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Married_freq = df['Married'].value_counts(ascending=True)\n",
    "print('Frequency Table for Married:')\n",
    "print(Married_freq)\n",
    "\n",
    "P_by_MaritalStat = df.pivot_table(values='Loan_Status', index=['Married'], aggfunc=lambda x: x.map(\n",
    "    {'Y': 1, 'N': 0}).mean())\n",
    "print('\\nProbability of getting loan for Marital statuses:')\n",
    "print(P_by_MaritalStat)\n",
    "P_by_MaritalStat = P_by_MaritalStat.squeeze()\n",
    "\n",
    "fig = plt.figure(figsize=(8, 4))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.set_xlabel('Marital status')\n",
    "ax1.set_ylabel('Count of Applicants')\n",
    "ax1.set_title(\"Applicants by Marital status\")\n",
    "Married_freq.plot(kind='bar')\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "ax2.set_xlabel('Married')\n",
    "ax2.set_ylabel('Probability of getting loan')\n",
    "ax2.set_title(\"Probability of getting loan by marital status\")\n",
    "P_by_MaritalStat.plot(kind='bar')\n",
    "# chances of getting a loan are mildly higher (10 %) if the applicant is married\n",
    "\n",
    "MaritalStat_LoanStatus_comb_stacked = pd.crosstab(df['Married'], df['Loan_Status'])\n",
    "MaritalStat_LoanStatus_comb_stacked.plot(kind='bar', stacked=True, color=['red', 'blue'], grid=False)\n",
    "\n",
    "MarriedGender_LoanStatus_comb_stacked = pd.crosstab([df['Married'], df['Gender']], df['Loan_Status'])\n",
    "MarriedGender_LoanStatus_comb_stacked.plot(kind='bar', stacked=True, color=['red', 'blue'], grid=False)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SelfEmployed_freq = df['Self_Employed'].value_counts(ascending=True)\n",
    "print('Frequency Table for Self_Employed:')\n",
    "print(SelfEmployed_freq)\n",
    "\n",
    "P_by_SelfEmployed = df.pivot_table(values='Loan_Status', index=['Self_Employed'], aggfunc=lambda x: x.map(\n",
    "    {'Y': 1, 'N': 0}).mean())\n",
    "print('\\nProbability of getting loan if Self-Employed:')\n",
    "print(P_by_SelfEmployed)\n",
    "P_by_SelfEmployed = P_by_SelfEmployed.squeeze()\n",
    "\n",
    "fig = plt.figure(figsize=(8, 4))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.set_xlabel('Self-Employed')\n",
    "ax1.set_ylabel('Count of Applicants')\n",
    "ax1.set_title(\"Applicants by Self-Employed\")\n",
    "SelfEmployed_freq.plot(kind='bar')\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "ax2.set_xlabel('Self-Employed')\n",
    "ax2.set_ylabel('Probability of getting loan')\n",
    "ax2.set_title(\"Probability of getting loan if self-employed\")\n",
    "P_by_SelfEmployed.plot(kind='bar')\n",
    "# identical chances of getting a loan for self- and unself-employed applicants\n",
    "\n",
    "SelfEmpl_LoanStatus_comb_stacked = pd.crosstab(df['Self_Employed'], df['Loan_Status'])\n",
    "SelfEmpl_LoanStatus_comb_stacked.plot(kind='bar', stacked=True, color=['red', 'blue'], grid=False)\n",
    "\n",
    "SelfEmplGender_LoanStatus_comb_stacked = pd.crosstab([df['Self_Employed'], df['Gender']], df['Loan_Status'])\n",
    "SelfEmplGender_LoanStatus_comb_stacked.plot(kind='bar', stacked=True, color=['red', 'blue'], grid=False)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PropertyArea_freq = df['Property_Area'].value_counts(ascending=True)\n",
    "print('Frequency Table for property areas:')\n",
    "print(PropertyArea_freq)\n",
    "\n",
    "P_by_PropertyArea = df.pivot_table(values='Loan_Status', index=['Property_Area'], aggfunc=lambda x: x.map(\n",
    "    {'Y': 1, 'N': 0}).mean())\n",
    "print('\\nProbability of getting loan by property area:')\n",
    "print(P_by_PropertyArea)\n",
    "P_by_PropertyArea = P_by_PropertyArea.squeeze()\n",
    "\n",
    "fig = plt.figure(figsize=(8, 4))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.set_xlabel('Property area')\n",
    "ax1.set_ylabel('Count of Applicants')\n",
    "ax1.set_title(\"Applicants by property area\")\n",
    "PropertyArea_freq.plot(kind='bar')\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "ax2.set_xlabel('Property area')\n",
    "ax2.set_ylabel('Probability of getting loan')\n",
    "ax2.set_title(\"Probability of getting loan by property area\")\n",
    "P_by_PropertyArea.plot(kind='bar')\n",
    "# chances of getting a loan are best for applicants living semirural areas\n",
    "\n",
    "PropertyArea_LoanStatus_comb_stacked = pd.crosstab(df['Property_Area'], df['Loan_Status'])\n",
    "PropertyArea_LoanStatus_comb_stacked.plot(kind='bar', stacked=True, color=['red', 'blue'], grid=False)\n",
    "\n",
    "PropertyAreaGender_LoanStatus_comb_stacked = pd.crosstab([df['Property_Area'], df['Gender']], df['Loan_Status'])\n",
    "PropertyAreaGender_LoanStatus_comb_stacked.plot(kind='bar', stacked=True, color=['red', 'blue'], grid=False)\n",
    "plt.tight_layout()\n",
    "\n",
    "PropertyAreaMarried_LoanStatus_comb_stacked = pd.crosstab([df['Property_Area'], df['Married']], df['Loan_Status'])\n",
    "PropertyAreaMarried_LoanStatus_comb_stacked.plot(kind='bar', stacked=True, color=['red', 'blue'], grid=False)\n",
    "plt.tight_layout()\n",
    "# semiurban + married is best combo, rural + no married & urban + no married are the worst\n",
    "\n",
    "PropertyAreaEducation_LoanStatus_comb_stacked = pd.crosstab([df['Property_Area'], df['Education']], df['Loan_Status'])\n",
    "PropertyAreaEducation_LoanStatus_comb_stacked.plot(kind='bar', stacked=True, color=['red', 'blue'], grid=False)\n",
    "plt.tight_layout()\n",
    "# urban + not graduated and rural + not graduated are worst combos for chances of getting loan\n",
    "# semiurban + graduated is the best combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Education_freq = df['Education'].value_counts(ascending=True)\n",
    "print('Frequency Table for education:')\n",
    "print(Education_freq)\n",
    "\n",
    "P_by_Education = df.pivot_table(values='Loan_Status', index=['Education'], aggfunc=lambda x: x.map(\n",
    "    {'Y': 1, 'N': 0}).mean())\n",
    "print('\\nProbability of getting loan by education:')\n",
    "print(P_by_Education)\n",
    "P_by_Education = P_by_Education.squeeze()\n",
    "\n",
    "fig = plt.figure(figsize=(8, 4))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.set_xlabel('Education')\n",
    "ax1.set_ylabel('Count of Applicants')\n",
    "ax1.set_title(\"Applicants by education\")\n",
    "Education_freq.plot(kind='bar')\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "ax2.set_xlabel('Education')\n",
    "ax2.set_ylabel('Probability of getting loan')\n",
    "ax2.set_title(\"Probability of getting loan by education\")\n",
    "P_by_Education.plot(kind='bar')\n",
    "# chances of getting a loan are better for more educated applicants\n",
    "\n",
    "Education_LoanStatus_comb_stacked = pd.crosstab(df['Education'], df['Loan_Status'])\n",
    "Education_LoanStatus_comb_stacked.plot(kind='bar', stacked=True, color=['red', 'blue'], grid=False)\n",
    "\n",
    "EducationGender_LoanStatus_comb_stacked = pd.crosstab([df['Education'], df['Gender']], df['Loan_Status'])\n",
    "EducationGender_LoanStatus_comb_stacked.plot(kind='bar', stacked=True, color=['red', 'blue'], grid=False)\n",
    "plt.tight_layout()\n",
    "# graduated + male lifts chances of getting loan compared to other combos\n",
    "\n",
    "EducationMarried_LoanStatus_comb_stacked = pd.crosstab([df['Education'], df['Married']], df['Loan_Status'])\n",
    "EducationMarried_LoanStatus_comb_stacked.plot(kind='bar', stacked=True, color=['red', 'blue'], grid=False)\n",
    "plt.tight_layout()\n",
    "# graduated + married lifts chances of getting loan compared to other combos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------Data munging-------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------Checking missing values---------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of missing values in dataframe column\n",
    "df.apply(lambda x: sum(x.isnull()),axis=0)\n",
    "\n",
    "# Education, ApplicantIncome, CoapplicantIncome, PropertyArea, LoanStatus with 0 missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self_Employed\n",
    "\n",
    "# 32 missing values\n",
    "# 500 non-self-employed (86 %) and 82 self-employed (14 %)\n",
    "\n",
    "# It seems that median incomes of self-employed persons are higher than non-self-employed people\n",
    "df.pivot_table(values='ApplicantIncome', index='Credit_History', columns='Self_Employed', aggfunc=np.median)\n",
    "\n",
    "df.loc[df['ApplicantIncome'] & (df['Self_Employed'] == 'Yes')].median()\n",
    "# median income is 5677 for self-employed\n",
    "df.loc[df['ApplicantIncome'] & (df['Self_Employed'] == 'No')].median()\n",
    "# median income is 3588 for self-employed\n",
    "\n",
    "# if person's incomes exceed median income of self-employed, person get's self-employed status\n",
    "df['Self_Employed'].loc[(df['ApplicantIncome'] > 5677)].fillna('Yes', inplace=True)\n",
    "# rest get status of non-self-employed\n",
    "df['Self_Employed'].fillna('No', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoanAmount\n",
    "\n",
    "# replace missing values with mean: df['LoanAmount'].fillna(df['LoanAmount'].mean(), inplace=True)\n",
    "\n",
    "# A key hypothesis is that the whether a person is educated or self-employed \n",
    "# can combine to give a good estimate of loan amount.\n",
    "df.boxplot(column='LoanAmount', by=['Education', 'Self_Employed'])\n",
    "plt.tight_layout()\n",
    "# some variations in the median of loan amount for each group and this can be used to impute the values\n",
    "\n",
    "# create a Pivot table, which provides us median values for all the groups of unique values \n",
    "# of Self_Employed and Education features\n",
    "table = df.pivot_table(values='LoanAmount', index='Self_Employed' ,columns='Education', aggfunc=np.median)\n",
    "# Define function to return value of this pivot_table\n",
    "def fage(x):\n",
    " return table.loc[x['Self_Employed'],x['Education']]\n",
    "# Replace missing values of LoanAmounts\n",
    "df['LoanAmount'].fillna(df[df['LoanAmount'].isnull()].apply(fage, axis=1), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next Married\n",
    "\n",
    "df['Married'].value_counts()\n",
    "# Circa 65 % are married and circa 35 % are not. 3 missing values\n",
    "# Let's replace 2 NaN:s in Married column with 'Yes' and 1 with 'No'.   \n",
    "df['Married'].fillna('Yes', limit=2, inplace=True)\n",
    "df['Married'].fillna('No', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender\n",
    "\n",
    "df['Gender'].value_counts()\n",
    "# About 82 % are males and 18 % females, 13 missing values\n",
    "# let's replace missing values with same proportions: 11 Males and 2 Females\n",
    "df['Gender'].fillna('Male', limit=11, inplace=True)\n",
    "df['Gender'].fillna('Female', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependents\n",
    "\n",
    "# Hypothesis is that amount of dependents depends on marital status, education and area of property\n",
    "pd.crosstab(df['Dependents'], [df['Married'], df['Education'], df['Property_Area']])\n",
    "# 0 dependents is most common in dataset, \n",
    "# but married, graduated people living in semiurban or urban\n",
    "# areas are more likely to have 1 or 2 dependents than others\n",
    "\n",
    "# ApplicantIncome might affect on the amount of dependents\n",
    "df.pivot_table(values='ApplicantIncome', index='Dependents' ,columns='Education', aggfunc=np.median)\n",
    "# graduated people living in rural areas, whose income is over 5000, are more likely to have three or more dependents\n",
    "\n",
    "# Now let's fill missings\n",
    "# First, if person lives in rural area, her/his income is over 5000 and she is graduated, filling is made with 3+ \n",
    "df['Dependents'].loc[(df['Property_Area'] == 'Rural') & (df['Education'] == 'Graduate') & (df['ApplicantIncome'] > 5000)].fillna('3+', inplace=True)\n",
    "# Second married, graduated people living in urban or semiurban areas; filling is made with random dependent amount\n",
    "df['Dependents'].loc[(df['Property_Area'] != 'Rural') & (df['Education'] == 'Graduate') & (df['Married'] == 'Yes')].fillna(lambda x: np.random.choice(df[df['Dependents'] != np.nan][\"Dependents\"]), inplace=True)\n",
    "    \n",
    "# And rest of the missing values are replaces with 0 dependents, which is the most common value\n",
    "df['Dependents'].fillna(df['Dependents'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loan_Amount_Term\n",
    "\n",
    "# Get's replaced by the most common duration (mode)\n",
    "df['Loan_Amount_Term'].fillna(df['Loan_Amount_Term'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credit_History\n",
    "\n",
    "df['Credit_History'].value_counts()\n",
    "# Circa 84 %'s credit history meets the guidelines whereas 16 %'s doesn't\n",
    "# 50 missing values\n",
    "\n",
    "# let's replace 8 (16 %) missing values with 0.0 and 42 missing values with 1.0\n",
    "df['Credit_History'].fillna(0.0, limit=8, inplace=True)\n",
    "df['Credit_History'].fillna(1.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------Handling extreme values--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loan Amount\n",
    "\n",
    "df['LoanAmount'].hist(bins=50)\n",
    "df.boxplot(column='LoanAmount')\n",
    "# Obvious extreme values\n",
    "# let’s try a log transformation to nullify their effect\n",
    "df['LoanAmount_log'] = np.log(df['LoanAmount'])\n",
    "df['LoanAmount_log'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applicant Income\n",
    "\n",
    "df['ApplicantIncome'].hist(bins=50)\n",
    "df.boxplot(column='ApplicantIncome')\n",
    "# Obvious extreme values\n",
    "\n",
    "# One intuition can be that some applicants have lower income but strong support Co-applicants. \n",
    "# So it might be a good idea to combine both incomes as total income and take a log transformation of the same.\n",
    "df['TotalIncome'] = df['ApplicantIncome'] + df['CoapplicantIncome']\n",
    "df['TotalIncome'].hist(bins=50) \n",
    "df['TotalIncome_log'] = np.log(df['TotalIncome'])\n",
    "df['TotalIncome_log'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make a new variable that measures applicants capability of paying back her/his loan\n",
    "df['LoanAmount/TotalIncome'] = df['LoanAmount'] / df['TotalIncome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------Building predictive models-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn requires all inputs to be numeric, we should convert all our categorical variables \n",
    "# into numeric by encoding the categories\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "var_mod = ['Gender','Married','Dependents','Education','Self_Employed','Property_Area','Loan_Status']\n",
    "le = LabelEncoder()\n",
    "for i in var_mod:\n",
    "    df[i] = le.fit_transform(df[i])\n",
    "df.dtypes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import models from scikit learn module:\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generic function for making a classification model and accessing performance:\n",
    "def classification_model(model, data, predictors, outcome):\n",
    "  #Fit the model:\n",
    "  model.fit(data[predictors],data[outcome])\n",
    "  \n",
    "  #Make predictions on training set:\n",
    "  predictions = model.predict(data[predictors])\n",
    "  \n",
    "  #Print accuracy\n",
    "  accuracy = metrics.accuracy_score(predictions,data[outcome])\n",
    "  print (\"Accuracy : %s\" % \"{0:.3%}\".format(accuracy))\n",
    "\n",
    "  #Perform k-fold cross-validation with 5 folds\n",
    "  kf = KFold(n_splits=5)\n",
    "  error = []\n",
    "  for train, test in kf.split(data):\n",
    "    # Filter training data\n",
    "    train_predictors = (data[predictors].iloc[train,:])\n",
    "    \n",
    "    # The target we're using to train the algorithm.\n",
    "    train_target = data[outcome].iloc[train]\n",
    "    \n",
    "    # Training the algorithm using the predictors and target.\n",
    "    model.fit(train_predictors, train_target)\n",
    "    \n",
    "    #Record error from each cross-validation run\n",
    "    error.append(model.score(data[predictors].iloc[test,:], data[outcome].iloc[test]))\n",
    " \n",
    "  print (\"Cross-Validation Score : %s\" % \"{0:.3%}\".format(np.mean(error)))\n",
    "\n",
    "  #Fit the model again so that it can be refered outside the function:\n",
    "  model.fit(data[predictors],data[outcome])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------Logistic regression---------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The chances of getting a loan will be higher for:\n",
    "#  Applicants having a credit history (remember we observed this in exploration?)\n",
    "#  Applicants with higher applicant and co-applicant incomes\n",
    "#  Applicants with higher education level\n",
    "#  Properties in urban areas with high growth perspectives\n",
    "\n",
    "outcome_var = 'Loan_Status'\n",
    "model = LogisticRegression()\n",
    "predictor_var = ['Credit_History']\n",
    "classification_model(model, df,predictor_var,outcome_var)\n",
    "# Accuracy : 80.945%, Cross-Validation Score : 80.946%\n",
    "\n",
    "#We can try different combination of variables:\n",
    "predictor_var = ['Credit_History','Education','Married','Self_Employed','Property_Area']\n",
    "classification_model(model, df,predictor_var,outcome_var)\n",
    "# Accuracy : 80.945%, Cross-Validation Score : 80.946%\n",
    "\n",
    "# Accuracy or cross-validation did not improve with additional or alternative variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------Decision tree-------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "predictor_var = ['Credit_History', 'Gender','Married','Education']\n",
    "classification_model(model, df,predictor_var,outcome_var)\n",
    "# Accuracy : 80.945%, Cross-Validation Score : 80.946%\n",
    "\n",
    "# Here the model based on categorical variables is unable to \n",
    "# have an impact because Credit History is dominating over them. Let’s try a few numerical variables:\n",
    "# We can try different combination of variables:\n",
    "predictor_var = ['Credit_History','Loan_Amount_Term','LoanAmount_log']\n",
    "classification_model(model, df,predictor_var,outcome_var)\n",
    "# Accuracy : 89.088%, Cross-Validation Score : 69.535%\n",
    "\n",
    "predictor_var = ['Credit_History', 'LoanAmount/TotalIncome', 'Loan_Amount_Term']\n",
    "classification_model(model, df,predictor_var,outcome_var)\n",
    "# Accuracy : 100.000%, Cross-Validation Score : 69.712%\n",
    "\n",
    "predictor_var = ['Credit_History', 'LoanAmount/TotalIncome', 'Loan_Amount_Term', 'Property_Area']\n",
    "classification_model(model, df,predictor_var,outcome_var)\n",
    "# Accuracy : 100.000%, Cross-Validation Score : 71.172%\n",
    "\n",
    "predictor_var = ['Credit_History', 'LoanAmount/TotalIncome', 'Loan_Amount_Term', 'Property_Area', 'Self_Employed']\n",
    "classification_model(model, df,predictor_var,outcome_var)\n",
    "# Accuracy : 100.000%, Cross-Validation Score : 71.661%\n",
    "\n",
    "# Accuracy got better, but cross-validation score got worse when adding up more variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------Random forest----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100)\n",
    "predictor_var = ['Gender', 'Married', 'Dependents', 'Education',\n",
    "       'Self_Employed', 'Loan_Amount_Term', 'Credit_History', 'Property_Area',\n",
    "        'LoanAmount_log','TotalIncome_log']\n",
    "classification_model(model, df,predictor_var,outcome_var)\n",
    "# Accuracy : 100.000%, Cross-Validation Score : 78.015%\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "predictor_var = ['Gender', 'Married', 'Dependents', 'Education',\n",
    "       'Self_Employed', 'Loan_Amount_Term', 'Credit_History', 'Property_Area',\n",
    "        'LoanAmount_log','TotalIncome_log', 'LoanAmount/TotalIncome']\n",
    "classification_model(model, df,predictor_var,outcome_var)\n",
    "# Accuracy : 100.000%, Cross-Validation Score : 78.339%\n",
    "\n",
    "\n",
    "# Let's try to correct overfitting problem\n",
    "\n",
    "#Create a series with feature importances:\n",
    "featimp = pd.Series(model.feature_importances_, index=predictor_var).sort_values(ascending=False)\n",
    "print (featimp)\n",
    "\n",
    "# Let’s use the top 5 variables for creating a model. Also, we will modify the parameters \n",
    "# of random forest model a little bit:\n",
    "model = RandomForestClassifier(n_estimators=25, min_samples_split=25, max_depth=7, max_features=1)\n",
    "predictor_var = ['Credit_History', 'LoanAmount/TotalIncome', 'TotalIncome_log','LoanAmount_log', 'Dependents']\n",
    "classification_model(model, df,predictor_var,outcome_var)\n",
    "# Accuracy : 82.573%, Cross-Validation Score : 80.292%\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=25, min_samples_split=25, max_depth=7, max_features=1)\n",
    "predictor_var = ['Credit_History', 'LoanAmount/TotalIncome', 'TotalIncome_log','LoanAmount_log', 'Dependents', 'Property_Area']\n",
    "classification_model(model, df,predictor_var,outcome_var)\n",
    "# Accuracy : 83.876%, Cross-Validation Score : 80.620%\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=25, min_samples_split=25, max_depth=7, max_features=1)\n",
    "predictor_var = ['Credit_History', 'LoanAmount/TotalIncome', 'Dependents', 'Property_Area']\n",
    "classification_model(model, df,predictor_var,outcome_var)\n",
    "# Accuracy : 83.876%, Cross-Validation Score : 81.109%\n",
    "# Best Cross-Validation Score!!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
